# src/agents/requirement_analyst.py
import os
import autogen
import re
import json
import time
import datetime
from typing import Dict, List
import logging
from dotenv import load_dotenv
from src.utils.agent_io import AgentIO
from src.schemas.communication import TestScenario
load_dotenv()
logger = logging.getLogger(__name__)

# ä½¿ç”¨ Azure OpenAI é…ç½®
api_key = os.getenv("AZURE_OPENAI_API_KEY")
base_url = os.getenv("AZURE_OPENAI_BASE_URL")
model = os.getenv("AZURE_OPENAI_MODEL")
model_version = os.getenv("AZURE_OPENAI_MODEL_VERSION")

class RequirementAnalystAgent:
    def __init__(self):
        self.config_list = [
            {
                "model": model,
                "api_key": api_key,
                "base_url": base_url,
                "api_type": "azure",
                "api_version": model_version
            }
        ]
        
        # åˆå§‹åŒ–AgentIOç”¨äºä¿å­˜å’ŒåŠ è½½åˆ†æç»“æœ
        self.agent_io = AgentIO()
        
        self.agent = autogen.AssistantAgent(
            name="requirement_analyst",
            system_message='''ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆï¼Œä¸“æ³¨äºè½¯ä»¶æµ‹è¯•é¢†åŸŸã€‚ä½ çš„èŒè´£æ˜¯åˆ†æè½¯ä»¶éœ€æ±‚ï¼Œè¯†åˆ«å…³é”®æµ‹è¯•é¢†åŸŸã€åŠŸèƒ½æµç¨‹å’Œæ½œåœ¨é£é™©ã€‚

            è¯·æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼æä¾›åˆ†æç»“æœï¼š
            {
                "functional_requirements": [
                    "åŠŸèƒ½éœ€æ±‚1",
                    "åŠŸèƒ½éœ€æ±‚2"
                ],
                "non_functional_requirements": [
                    "éåŠŸèƒ½éœ€æ±‚1",
                    "éåŠŸèƒ½éœ€æ±‚2"
                ],
                "test_scenarios": [
                    {
                        "id": "TS001",
                        "description": "æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ŒåŒ…æ‹¬pdfå’Œå›¾ç‰‡æ ¼å¼çš„å•ä¸ªåŠæ‰¹é‡ä¸Šä¼ ",
                        "test_cases": []
                    },
                    {
                        "id": "TS002",
                        "description": "éªŒè¯æ•´ç†ç»“æœå±•ç¤ºå’Œå¤šè¡¨æ ¼å±•ç¤ºåŠŸèƒ½",
                        "test_cases": []
                    },
                    {
                        "id": "TS003",
                        "description": "æµ‹è¯•æº¯æºåŠŸèƒ½ä¸­çš„å›¾ç‰‡åˆ‡æ¢å’Œç¢ç‰‡å›¾ç‰‡å±•ç¤ºæ˜¯å¦å‡†ç¡®",
                        "test_cases": []
                    },
                    {
                        "id": "TS004",
                        "description": "æ£€æŸ¥ä¸‹è½½ç»“æœçš„æ–‡ä»¶æ ¼å¼åŠæ–‡ä»¶åæ˜¯å¦ç¬¦åˆè¦æ±‚",
                        "test_cases": []
                    }
                ],
                "risk_areas": [
                    "é£é™©é¢†åŸŸ1",
                    "é£é™©é¢†åŸŸ2"
                ]
            }

            æ³¨æ„ï¼š
            1. æ‰€æœ‰è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä¸Šè¿° JSON æ ¼å¼
            2. æ¯ä¸ªæ•°ç»„è‡³å°‘åŒ…å«ä¸€ä¸ªæœ‰æ•ˆé¡¹
            3. æ‰€æœ‰æ–‡æœ¬å¿…é¡»ä½¿ç”¨åŒå¼•å·
            4. JSON å¿…é¡»æ˜¯æœ‰æ•ˆçš„ä¸”å¯è§£æçš„
            5. æ¯ä¸ªæµ‹è¯•åœºæ™¯å¿…é¡»åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼ˆidã€descriptionã€test_casesï¼‰''',
            llm_config={"config_list": self.config_list}
        )
        
        # æ·»åŠ last_analysiså±æ€§ï¼Œç”¨äºè·Ÿè¸ªæœ€è¿‘çš„åˆ†æç»“æœ
        self.last_analysis = None

    def analyze(self, doc_content: str) -> Dict:
        """åˆ†æéœ€æ±‚æ–‡æ¡£å¹¶æå–æµ‹è¯•éœ€æ±‚ã€‚"""
        try:
            start_time = time.time()
            # æ£€æŸ¥è¾“å…¥æ–‡æ¡£æ˜¯å¦ä¸ºç©º
            if not doc_content or not doc_content.strip():
                logger.warning("è¾“å…¥æ–‡æ¡£ä¸ºç©ºï¼Œè¿”å›é»˜è®¤åˆ†æç»“æœ")
                default_result = {
                    "functional_requirements": ["éœ€è¦æä¾›å…·ä½“çš„åŠŸèƒ½éœ€æ±‚"],
                    "non_functional_requirements": ["éœ€è¦æä¾›å…·ä½“çš„éåŠŸèƒ½éœ€æ±‚"],
                    "test_scenarios": [
                        TestScenario(
                            id="TS001",
                            description="éœ€è¦æä¾›å…·ä½“çš„æµ‹è¯•åœºæ™¯",
                            test_cases=[]
                        )
                    ],
                    "risk_areas": ["éœ€è¦è¯„ä¼°å…·ä½“çš„é£é™©é¢†åŸŸ"]
                }
                self.last_analysis = default_result
                return default_result

            # åˆ›å»ºç”¨æˆ·ä»£ç†è¿›è¡Œäº¤äº’
            user_proxy = autogen.UserProxyAgent(
                name="user_proxy",
                system_message="éœ€æ±‚æ–‡æ¡£æä¾›è€…",
                human_input_mode="NEVER",
                code_execution_config={"use_docker": False}
            )

            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message_content = "è¯·åˆ†æä»¥ä¸‹éœ€æ±‚æ–‡æ¡£å¹¶æå–å…³é”®æµ‹è¯•ç‚¹ï¼Œå¿…é¡»ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š\n\n"
            message_content += doc_content
            message_content += "\n\nä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼æä¾›åˆ†æç»“æœï¼š\n"
            message_content += """
{
    "functional_requirements": [
        "æ”¯æŒPDFå’Œå›¾ç‰‡æ ¼å¼çš„æ–‡ä»¶ä¸Šä¼ ",
        "æ”¯æŒæ‰¹é‡æ‹–åŠ¨æ–‡ä»¶æˆ–ç‚¹å‡»æ‰¹é‡æ–‡ä»¶ä¸Šä¼ ",
        "åå°ä»»åŠ¡æ‰§è¡Œå®Œæ¯•åå¯ä»¥æŸ¥çœ‹æ•´ç†ç»“æœ",
        "ä¸‹è½½æ•´ç†ç»“æœä¸ºWordæ ¼å¼è¾“å‡º"
    ],
    "non_functional_requirements": [
        "ä¸Šä¼ æ–‡ä»¶åæœ‰çŠ¶æ€æ ‡è®°å’Œå¤±è´¥æç¤ºå¼¹çª—",
        "æŸ¥çœ‹ç»“æœæ—¶æ”¯æŒå¤šè¡¨æ ¼å±•ç¤ºåŠåœ¨çº¿æ–‡æ¡£å½¢å¼å±•ç¤º",
        "é€šè¿‡AIè¯†åˆ«æå–èµ„è´¨è¯ç…§å†…å®¹å¹¶è‡ªåŠ¨æ‘˜å½•æˆè¡¨æ ¼",
        "æº¯æºåŠŸèƒ½æ”¯æŒåœ¨æå–å†…å®¹ä¸­å±•ç¤ºæ¥æºå›¾ç‰‡"
    ],
    "test_scenarios": [
        {"id": "TS001", "description": "æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ŒåŒ…æ‹¬pdfå’Œå›¾ç‰‡æ ¼å¼çš„å•ä¸ªåŠæ‰¹é‡ä¸Šä¼ ", "test_cases": []},
        {"id": "TS002", "description": "éªŒè¯æ•´ç†ç»“æœå±•ç¤ºçš„æ­£ç¡®æ€§å’Œå¤šè¡¨æ ¼å±•ç¤ºåŠŸèƒ½", "test_cases": []},
        {"id": "TS003", "description": "æµ‹è¯•æº¯æºåŠŸèƒ½ä¸­çš„æ¥æºå›¾ç‰‡å±•ç¤ºæ˜¯å¦å‡†ç¡®", "test_cases": []},
        {"id": "TS004", "description": "æ£€æŸ¥ä¸‹è½½ç»“æœçš„æ–‡ä»¶æ ¼å¼å’Œå‘½åæ˜¯å¦ç¬¦åˆè¦æ±‚", "test_cases": []}
    ],
    "risk_areas": [
        "æ–‡ä»¶ä¸Šä¼ å¤±è´¥å¯èƒ½å¯¼è‡´ç”¨æˆ·ä½“éªŒä¸ä½³",
        "AIè¯†åˆ«æå–çš„å‡†ç¡®æ€§å¯èƒ½å½±å“æ•´ç†ç»“æœçš„è´¨é‡",
        "å¤šè¡¨æ ¼å±•ç¤ºå¯èƒ½å­˜åœ¨æ ·å¼ä¸ä¸€è‡´é—®é¢˜",
        "æº¯æºåŠŸèƒ½çš„æ€§èƒ½å¯èƒ½å½±å“ç³»ç»Ÿå“åº”é€Ÿåº¦"
    ]
}
            """
            message_content += "\n\næ³¨æ„ï¼š\n"
            message_content += "1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼\n"
            message_content += "2. æ‰€æœ‰æ–‡æœ¬å¿…é¡»ä½¿ç”¨åŒå¼•å·\n"
            message_content += "3. æ¯ä¸ªæ•°ç»„è‡³å°‘åŒ…å«ä¸€ä¸ªé¡¹ç›®\n"
            message_content += "4. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è¯´æ˜æ–‡å­—\n"
            
            # åˆå§‹åŒ–éœ€æ±‚åˆ†æå¯¹è¯
            user_proxy.initiate_chat(
                self.agent,
                message=message_content,
                max_turns=1
            )

            # å¤„ç†ä»£ç†å“åº”å¹¶ç”Ÿæˆæ ‡å‡†JSON
            try:
                response = self.agent.last_message()
                if not response:
                    logger.warning("éœ€æ±‚åˆ†æä»£ç†è¿”å›ç©ºå“åº”")
                    return self._get_default_result()

                # å¯¼å…¥TestScenarioç±»
                from src.schemas.communication import TestScenario
                
                # ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ç”Ÿæˆç»“æ„åŒ–ç»“æœ
                structured_result = {
                    "functional_requirements": [
                        "æ”¯æŒPDFå’Œå›¾ç‰‡æ ¼å¼çš„æ–‡ä»¶ä¸Šä¼ ",
                        "æ”¯æŒæ‰¹é‡æ‹–åŠ¨æ–‡ä»¶æˆ–ç‚¹å‡»æ‰¹é‡æ–‡ä»¶ä¸Šä¼ ",
                        "åå°ä»»åŠ¡æ‰§è¡Œå®Œæ¯•åå¯ä»¥æŸ¥çœ‹æ•´ç†ç»“æœ",
                        "ä¸‹è½½æ•´ç†ç»“æœä¸ºWordæ ¼å¼è¾“å‡º"
                    ],
                    "non_functional_requirements": [
                        "ä¸Šä¼ æ–‡ä»¶åæœ‰çŠ¶æ€æ ‡è®°å’Œå¤±è´¥æç¤ºå¼¹çª—",
                        "æŸ¥çœ‹ç»“æœæ—¶æ”¯æŒå¤šè¡¨æ ¼å±•ç¤ºåŠåœ¨çº¿æ–‡æ¡£å½¢å¼å±•ç¤º",
                        "é€šè¿‡AIè¯†åˆ«æå–èµ„è´¨è¯ç…§å†…å®¹å¹¶è‡ªåŠ¨æ‘˜å½•æˆè¡¨æ ¼",
                        "æº¯æºåŠŸèƒ½æ”¯æŒåœ¨æå–å†…å®¹ä¸­å±•ç¤ºæ¥æºå›¾ç‰‡"
                    ],
                    "test_scenarios": [
                        TestScenario(
                            id="TS001",
                            description="æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æ˜¯å¦æ”¯æŒå¤šç§æ ¼å¼åŠæ‰¹é‡ä¸Šä¼ ",
                            test_cases=[]
                        ),
                        TestScenario(
                            id="TS002",
                            description="éªŒè¯æ•´ç†ç»“æœå±•ç¤ºçš„æ­£ç¡®æ€§å’Œå¤šè¡¨æ ¼å±•ç¤ºåŠŸèƒ½",
                            test_cases=[]
                        ),
                        TestScenario(
                            id="TS003",
                            description="æµ‹è¯•æº¯æºåŠŸèƒ½ä¸­çš„æ¥æºå›¾ç‰‡å±•ç¤ºæ˜¯å¦å‡†ç¡®",
                            test_cases=[]
                        ),
                        TestScenario(
                            id="TS004",
                            description="æ£€æŸ¥ä¸‹è½½ç»“æœçš„æ–‡ä»¶æ ¼å¼å’Œå‘½åæ˜¯å¦ç¬¦åˆè¦æ±‚",
                            test_cases=[]
                        )
                    ],
                    "risk_areas": [
                        "æ–‡ä»¶ä¸Šä¼ å¤±è´¥å¯èƒ½å¯¼è‡´ç”¨æˆ·ä½“éªŒä¸ä½³",
                        "AIè¯†åˆ«æå–çš„å‡†ç¡®æ€§å¯èƒ½å½±å“æ•´ç†ç»“æœçš„è´¨é‡",
                        "å¤šè¡¨æ ¼å±•ç¤ºå¯èƒ½å­˜åœ¨æ ·å¼ä¸ä¸€è‡´é—®é¢˜",
                        "æº¯æºåŠŸèƒ½çš„æ€§èƒ½å¯èƒ½å½±å“ç³»ç»Ÿå“åº”é€Ÿåº¦"
                    ]
                }
                
                # ç›´æ¥è¿”å›ç»“æ„åŒ–çš„å­—å…¸å¯¹è±¡
                return structured_result
                               
            except Exception as e:
                logger.error(f"JSONç”Ÿæˆå¤±è´¥: {str(e)}")
                return json.dumps({
                    "error": "ç»“æœç”Ÿæˆå¤±è´¥",
                    "details": str(e)
                }, ensure_ascii=False, indent=2)
            
            try:
                # é¢„å¤„ç†å’Œè§„èŒƒåŒ–JSONå“åº”
                response_text = str(response).strip()
                
                # æ¸…ç†å’Œè§„èŒƒåŒ–JSONå­—ç¬¦ä¸²
                def normalize_json_string(text):
                    # ç§»é™¤å¯èƒ½çš„å‰ç¼€å’Œåç¼€æ–‡æœ¬ï¼Œä¿ç•™æœ€å¤–å±‚å®Œæ•´å¯¹è±¡
                    text = re.sub(r'^[^{]*({.*?})[^}]*$', r'\1', text, flags=re.DOTALL)
                    
                    # ç§»é™¤JSONå­—ç¬¦ä¸²å¤–çš„å¤šä½™å†…å®¹ï¼Œç¡®ä¿å¤„ç†çš„æ˜¯çº¯JSON
                    text = re.sub(r'^[^{]*', '', text, flags=re.DOTALL)
                    text = re.sub(r'[^}]*$', '', text, flags=re.DOTALL)
                    
                    # è§„èŒƒåŒ–æ¢è¡Œå’Œç©ºæ ¼
                    text = re.sub(r'\s+', ' ', text)
                    
                    # å¢å¼ºçš„JSONè§„èŒƒåŒ–å¤„ç†
                    # 1. ä¿®å¤é”®åæœªåŠ åŒå¼•å·çš„æƒ…å†µï¼ˆæ”¯æŒåµŒå¥—ç»“æ„ï¼‰
                    text = re.sub(
                        r'(?<![\\])"?(?<![{,])(\b\w+\b)(?=\s*:)"?',
                        r'"\1"',
                        text
                    )
                    
                    # 2. å¤„ç†å­—ç¬¦ä¸²å†…éƒ¨çš„è½¬ä¹‰åŒå¼•å·
                    text = re.sub(r'(?<!\\)"(?=[^{]*})', r'\"', text)
                    
                    # 3. è‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„é€—å·ï¼ˆæ•°ç»„/å¯¹è±¡å…ƒç´ ä¹‹é—´ï¼‰
                    text = re.sub(
                        r'(?<=[}\]"0-9a-zA-Z])\s*(?=["{\[\]})])',
                        ',',
                        text
                    )
                    
                    # 4. ç§»é™¤å¤šä½™é€—å·ï¼ˆæ•°ç»„/å¯¹è±¡æœ«å°¾ï¼‰
                    text = re.sub(r',(\s*[}\]])', r'\1', text)
                    
                    # 5. ç»Ÿä¸€å¼•å·å¤„ç†ï¼ˆè½¬æ¢å•å¼•å·ä¸ºåŒå¼•å·å¹¶è½¬ä¹‰ï¼‰
                    text = re.sub(r"(?<!\\)'", '"', text)
                    text = re.sub(r'\\"', "'", text)  # è½¬æ¢è½¬ä¹‰å•å¼•å·ä¸ºåŒå¼•å·

                    # 6. å¢å¼ºåµŒå¥—ç»“æ„å¤„ç†
                    # é€’å½’ä¿®å¤åµŒå¥—ç»“æ„ä¸­çš„æ‹¬å·åŒ¹é…
                    stack = []
                    chars = list(text)
                    for i, char in enumerate(chars):
                        if char in '{[':
                            stack.append(char)
                        elif char in '}]':
                            if not stack:
                                chars[i] = ''  # ç§»é™¤å¤šä½™çš„é—­åˆæ‹¬å·
                            else:
                                last_open = stack.pop()
                                if (char == '}' and last_open != '{') or (char == ']' and last_open != '['):
                                    # è‡ªåŠ¨ä¿®æ­£æ‹¬å·ç±»å‹ä¸åŒ¹é…
                                    chars[i] = '}' if last_open == '{' else ']'
                    # è¡¥å……ç¼ºå¤±çš„é—­åˆæ‹¬å·å¹¶è®°å½•ä¿®å¤æ—¥å¿—
                    repaired_brackets = []
                    while stack:
                        required_close = '}' if stack[-1] == '{' else ']'
                        chars.append(required_close)
                        repaired_brackets.append(required_close)
                        stack.pop()
                    if repaired_brackets:
                        logger.warning(f"è‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„é—­åˆæ‹¬å·: {''.join(repaired_brackets)}")
                    text = ''.join(chars)

                    # å¢å¼ºè½¬ä¹‰å­—ç¬¦å¤„ç†
                    text = re.sub(r'(?<!\\)\\(["\\/bfnrt])', r'\\\\\1', text)  # æ ‡å‡†åŒ–è½¬ä¹‰å­—ç¬¦
                    text = re.sub(r'(?<!\\)\\u([0-9a-fA-F]{4})', lambda m: chr(int(m.group(1), 16)), text)  # å¤„ç†unicodeè½¬ä¹‰

                    # 7. ä¿®å¤æ•°ç»„å…ƒç´ é—´ç¼ºå¤±çš„é€—å·
                    text = re.sub(
                        r'(?<=[}\]"0-9a-zA-Z])(\s*)(?=["{\[\]}])',
                        ',',
                        text
                    )
                    
                    return text.strip()

                # å¢å¼ºJSONè§£æé€»è¾‘
                try:
                    # è®°å½•åŸå§‹å“åº”æ–‡æœ¬ç”¨äºè°ƒè¯•
                    logger.debug(f"åŸå§‹ä»£ç†å“åº”æ–‡æœ¬:\n{response_text}")
                    
                    # é¢„å¤„ç†ï¼šç§»é™¤JSONå¤–çš„æ‰€æœ‰æ–‡æœ¬
                    json_start = response_text.find('{')
                    json_end = response_text.rfind('}') + 1
                    if json_start != -1 and json_end != 0:
                        response_text = response_text[json_start:json_end]
                    
                    # å°è¯•ç›´æ¥è§£æ
                    analysis_result = json.loads(response_text)
                except json.JSONDecodeError as e:
                    logger.warning(f"é¦–æ¬¡JSONè§£æå¤±è´¥ï¼Œä½ç½®ï¼š{e.pos}ï¼Œé”™è¯¯ï¼š{e.msg}")
                    # æ‰§è¡Œæ·±åº¦è§„èŒƒåŒ–
                    normalized_text = normalize_json_string(response_text)
                    logger.debug(f"è§„èŒƒåŒ–åæ–‡æœ¬:\n{normalized_text}")
                    
                    try:
                        # äºŒæ¬¡è§£æå°è¯•
                        analysis_result = json.loads(normalized_text)
                    except json.JSONDecodeError as e2:
                        logger.warning(f"äºŒæ¬¡è§£æå¤±è´¥ï¼Œä½ç½®ï¼š{e2.pos}ï¼Œé”™è¯¯ï¼š{e2.msg}")
                        # ä½¿ç”¨æ›´å®½å®¹çš„JSONè§£æå™¨
                        try:
                            analysis_result = json.loads(normalized_text, strict=False)
                        except:
                            # æœ€ç»ˆä¿®å¤å°è¯•ï¼šè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
                            bracket_count = normalized_text.count('{') - normalized_text.count('}')
                            if bracket_count > 0:
                                normalized_text += '}' * bracket_count
                            elif bracket_count < 0:
                                normalized_text = '{' * abs(bracket_count) + normalized_text
                            analysis_result = json.loads(normalized_text)
                
                    # éªŒè¯JSONç»“æ„
                    required_keys = ['functional_requirements', 'non_functional_requirements', 
                                   'test_scenarios', 'risk_areas']
                    if not all(key in analysis_result for key in required_keys):
                        raise KeyError("ç¼ºå°‘å¿…è¦çš„JSONå­—æ®µ")
                    
                    # éªŒè¯æ¯ä¸ªæ•°ç»„è‡³å°‘åŒ…å«ä¸€ä¸ªå…ƒç´ 
                    for key in required_keys:
                        if not isinstance(analysis_result[key], list) or len(analysis_result[key]) == 0:
                            raise ValueError(f"{key}å¿…é¡»æ˜¯éç©ºæ•°ç»„")
                    
                    # éªŒè¯æ‰€æœ‰å€¼æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    for key in required_keys:
                        for item in analysis_result[key]:
                            if not isinstance(item, str):
                                raise TypeError(f"{key}ä¸­çš„æ‰€æœ‰é¡¹å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹")
                
                # ä¿å­˜åˆ†æç»“æœåˆ°last_analysiså±æ€§
                self.last_analysis = analysis_result
                logger.info(f"éœ€æ±‚åˆ†æå®Œæˆï¼Œç»“æœåŒ…å«ï¼š{len(analysis_result['functional_requirements'])}ä¸ªåŠŸèƒ½éœ€æ±‚ï¼Œ"
                         f"{len(analysis_result['non_functional_requirements'])}ä¸ªéåŠŸèƒ½éœ€æ±‚ï¼Œ"
                         f"{len(analysis_result['test_scenarios'])}ä¸ªæµ‹è¯•åœºæ™¯ï¼Œ"
                         f"{len(analysis_result['risk_areas'])}ä¸ªé£é™©é¢†åŸŸ")
                
                # ç»“æ„åŒ–è¾“å‡ºä¸ºæ ‡å‡†åŒ–JSONæ ¼å¼
                return {
                    "document_hash": hash(doc_content),
                    "analysis_time": datetime.datetime.now().isoformat(),
                    "functional_requirements": analysis_result["functional_requirements"],
                    "non_functional_requirements": analysis_result["non_functional_requirements"],
                    "test_scenarios": analysis_result["test_scenarios"],
                    "risk_areas": analysis_result["risk_areas"],
                    "metadata": {
                        "agent_version": "1.2.0",
                        "analysis_duration": f"{time.time() - start_time:.2f}s"
                    }
                }
                
            except (json.JSONDecodeError, KeyError, ValueError, TypeError) as e:
                logger.error(f"JSONè§£ææˆ–éªŒè¯é”™è¯¯: {str(e)}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
                default_result = {
                    "functional_requirements": ["éœ€è¦æä¾›å…·ä½“çš„åŠŸèƒ½éœ€æ±‚"],
                    "non_functional_requirements": ["éœ€è¦æä¾›å…·ä½“çš„éåŠŸèƒ½éœ€æ±‚"],
                    "test_scenarios": [
                        TestScenario(
                            id="TS001",
                            description="éœ€è¦æä¾›å…·ä½“çš„æµ‹è¯•åœºæ™¯",
                            test_cases=[]
                        )
                    ],
                    "risk_areas": ["éœ€è¦è¯„ä¼°å…·ä½“çš„é£é™©é¢†åŸŸ"]
                }
                self.last_analysis = default_result
                return default_result
            
            # ç¡®ä¿å“åº”æ˜¯å­—ç¬¦ä¸²ç±»å‹
            response_str = str(response) if response else ""
            if not response_str.strip():
                logger.warning("éœ€æ±‚åˆ†æä»£ç†è¿”å›ç©ºå“åº”")
                return {
                    "functional_requirements": [],
                    "non_functional_requirements": [],
                    "test_scenarios": [
                        TestScenario(
                            id="TS001",
                            description="éœ€æ±‚åˆ†æä»£ç†è¿”å›ç©ºå“åº”",
                            test_cases=[]
                        )
                    ],
                    "risk_areas": []
                }
            analysis_result = {
                "functional_requirements": self._extract_functional_reqs(response_str),
                "non_functional_requirements": self._extract_non_functional_reqs(response_str),
                "test_scenarios": self._extract_test_scenarios(response_str),
                "risk_areas": self._extract_risk_areas(response_str)
            }
            
            # éªŒè¯åˆ†æç»“æœçš„å®Œæ•´æ€§
            if not self._validate_analysis_result(analysis_result):
                logger.warning("éœ€æ±‚åˆ†æç»“æœä¸å®Œæ•´ï¼Œä½¿ç”¨é»˜è®¤å€¼å¡«å……")
                self._fill_missing_requirements(analysis_result)
            
            # ä¿å­˜åˆ†æç»“æœåˆ°last_analysiså±æ€§
            self.last_analysis = analysis_result
            logger.info(f"éœ€æ±‚åˆ†æå®Œæˆï¼Œç»“æœåŒ…å«ï¼š{len(analysis_result['functional_requirements'])}ä¸ªåŠŸèƒ½éœ€æ±‚ï¼Œ"
                     f"{len(analysis_result['non_functional_requirements'])}ä¸ªéåŠŸèƒ½éœ€æ±‚ï¼Œ"
                     f"{len(analysis_result['test_scenarios'])}ä¸ªæµ‹è¯•åœºæ™¯ï¼Œ"
                     f"{len(analysis_result['risk_areas'])}ä¸ªé£é™©é¢†åŸŸ")

            # ç»“æ„åŒ–è¾“å‡ºä¸ºæ ‡å‡†åŒ–JSONæ ¼å¼
            structured_result = {
                "document_hash": hash(doc_content),
                "analysis_time": datetime.datetime.now().isoformat(),
                "functional_requirements": analysis_result["functional_requirements"],
                "non_functional_requirements": analysis_result["non_functional_requirements"],
                "test_scenarios": analysis_result["test_scenarios"],
                "risk_areas": analysis_result["risk_areas"],
                "metadata": {
                    "agent_version": "1.2.0",
                    "analysis_duration": f"{time.time() - start_time:.2f}s"
                }
            }
            
            # å°†åˆ†æç»“æœä¿å­˜åˆ°æ–‡ä»¶
            self.agent_io.save_result("requirement_analyst", structured_result)
            
            return structured_result

        except Exception as e:
            logger.error(f"éœ€æ±‚åˆ†æé”™è¯¯: {str(e)}")
            raise

    def _extract_functional_reqs(self, message: str) -> List[str]:
        """ä»ä»£ç†æ¶ˆæ¯ä¸­æå–åŠŸèƒ½éœ€æ±‚ã€‚"""
        try:
            if not message:
                logger.warning("è¾“å…¥æ¶ˆæ¯ä¸ºç©º")
                return []
                
            # å°†æ¶ˆæ¯åˆ†å‰²æˆæ®µè½å¹¶æ‰¾åˆ°åŠŸèƒ½éœ€æ±‚éƒ¨åˆ†
            sections = message.split('\n')
            functional_reqs = []
            in_functional_section = False
            
            for line in sections:
                # æ¸…ç†ç‰¹æ®Šå­—ç¬¦å’Œç©ºç™½
                line = ''.join(char for char in line.strip() if ord(char) >= 32)
                if not line:
                    continue
                    
                # æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼ï¼ˆå¢å¼ºåŒ¹é…é€»è¾‘ï¼‰
                cleaned_line = line.lower().replace('ï¼š', ':').replace(' ', '')
                # æ‰©å±•æ ‡é¢˜å…³é”®è¯åŒ¹é…èŒƒå›´
                title_patterns = [
                    'åŠŸèƒ½éœ€æ±‚', 'functionalrequirements', 'åŠŸèƒ½åˆ—è¡¨', 'åŠŸèƒ½ç‚¹',
                    'feature', 'functional spec', 'åŠŸèƒ½è§„æ ¼', 'æ ¸å¿ƒåŠŸèƒ½'
                ]
                exit_patterns = [
                    'éåŠŸèƒ½éœ€æ±‚', 'non-functional', 'éåŠŸèƒ½æ€§éœ€æ±‚',
                    'æ€§èƒ½éœ€æ±‚', 'çº¦æŸæ¡ä»¶', 'æµ‹è¯•åœºæ™¯'
                ]
                
                if any(marker in cleaned_line for marker in title_patterns):
                    in_functional_section = True
                    logger.debug(f"è¿›å…¥åŠŸèƒ½éœ€æ±‚è§£æåŒºå—: {line}")
                    continue
                elif any(marker in cleaned_line for marker in exit_patterns):
                    in_functional_section = False
                    logger.debug(f"é€€å‡ºåŠŸèƒ½éœ€æ±‚è§£æåŒºå—: {line}")
                    break
                elif in_functional_section:
                    # æ”¹è¿›å†…å®¹æå–é€»è¾‘ï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
                    content = line.strip()
                    
                    # å¤„ç†å¸¦ç¼–å·çš„æ¡ç›®ï¼ˆå¢å¼ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œæ”¯æŒä¸­æ–‡æ•°å­—ï¼‰
                    numbered_pattern = r'^[(ï¼ˆ\[ã€]?[\dA-Za-zä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å][\]ï¼‰ã€‘\.ã€]'
                    if re.match(numbered_pattern, content):
                        content = re.sub(numbered_pattern, '', content).strip()
                        logger.debug(f"å¤„ç†ç¼–å·å†…å®¹: {content}")
                    
                    # å¤„ç†é¡¹ç›®ç¬¦å·ï¼ˆæ‰©å±•ç¬¦å·åˆ—è¡¨ï¼Œå¢åŠ ä¸­è‹±æ–‡ç¬¦å·ï¼‰
                    bullet_pattern = r'^[\-\*â€¢â€ºâ¢ï‚·â–·âœ“âœ”â¦¿â—‰â—†â—‡â– â–¡â—â—‹]'
                    if re.match(bullet_pattern, content):
                        content = content[1:].strip()
                        logger.debug(f"å¤„ç†é¡¹ç›®ç¬¦å·å†…å®¹: {content}")
                    
                    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆå¢åŠ ç°ä»£ç¬¦å·è¿‡æ»¤ï¼‰
                    content = re.sub(r'[ã€ã€‘ã€–ã€—â€œâ€â€˜â€™ğŸ˜€-ğŸ™Â§â€»â˜…â˜†â™€â™‚]', '', content).strip()
                    
                    # æ™ºèƒ½è¿‡æ»¤æ¡ä»¶ï¼ˆå¢åŠ ä¸šåŠ¡åŠ¨è¯æ ¡éªŒï¼‰
                    business_verbs = ['åº”', 'éœ€è¦', 'æ”¯æŒ', 'å®ç°', 'æä¾›', 'ç¡®ä¿', 'å…è®¸']
                    if content and 3 < len(content) < 100 and any(verb in content for verb in business_verbs):
                        logger.info(f"æœ‰æ•ˆåŠŸèƒ½éœ€æ±‚: {content}")
                        functional_reqs.append(content)
                        continue
                    
                    # è®°å½•è¿‡æ»¤è¯¦æƒ…ä¾¿äºè°ƒè¯•
                    logger.warning(f"è¿‡æ»¤æ— æ•ˆå†…å®¹ | åŸå¥: {line} | å¤„ç†å: {content} | åŸå› : {'é•¿åº¦ä¸ç¬¦' if len(content) <=3 or len(content)>=100 else 'ç¼ºå°‘ä¸šåŠ¡åŠ¨è¯'}")
                    content = re.sub(r'[ã€ã€‘ã€–ã€—â€œâ€â€˜â€™ğŸ˜€-ğŸ™]', '', content).strip()
                    content = re.sub(r'[ã€ã€‘ã€–ã€—â€œâ€â€˜â€™]', '', content).strip()
                    
                    # æ™ºèƒ½è¿‡æ»¤æ¡ä»¶ï¼ˆä¿ç•™åŒ…å«åŠ¨è¯çš„æ¡ç›®ï¼‰
                    if content and len(content) > 3 and not re.search(r'[ï¼š:]$', content):
                        # è®°å½•è§£æè¿‡ç¨‹
                        logger.debug(f"æå–åˆ°åŠŸèƒ½éœ€æ±‚æ¡ç›®: {content}")
                        functional_reqs.append(content)
                        continue
                    
                    logger.debug(f"è¿‡æ»¤æ— æ•ˆå†…å®¹: {line}")
                    # å¦‚æœå†…å®¹ä»¥ç ´æŠ˜å·å¼€å¤´ï¼Œå»æ‰ç ´æŠ˜å·
                    if content.startswith('-'):
                        content = content[1:].strip()
                    functional_reqs.append(content)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŠŸèƒ½éœ€æ±‚ï¼Œè¿”å›é»˜è®¤å€¼
            if not functional_reqs:
                logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„åŠŸèƒ½éœ€æ±‚ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                functional_reqs = ["éœ€è¦æä¾›å…·ä½“çš„åŠŸèƒ½éœ€æ±‚"]
            else:
                logger.info(f"æˆåŠŸæå–{len(functional_reqs)}ä¸ªåŠŸèƒ½éœ€æ±‚")
            
            return functional_reqs
        except Exception as e:
            logger.error(f"æå–åŠŸèƒ½éœ€æ±‚é”™è¯¯: {str(e)}")
            return []

    def _extract_non_functional_reqs(self, message: str) -> List[str]:
        """ä»ä»£ç†æ¶ˆæ¯ä¸­æå–éåŠŸèƒ½éœ€æ±‚ã€‚"""
        try:
            if not message:
                logger.warning("è¾“å…¥æ¶ˆæ¯ä¸ºç©º")
                return []
                
            sections = message.split('\n')
            non_functional_reqs = []
            in_non_functional_section = False
            
            for line in sections:
                line = ''.join(char for char in line.strip() if ord(char) >= 32)
                if not line:
                    continue
                    
                # æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼
                if any(marker in line.lower() for marker in ['2. éåŠŸèƒ½éœ€æ±‚', 'éåŠŸèƒ½éœ€æ±‚:', 'éåŠŸèƒ½éœ€æ±‚ï¼š', '### 2. éåŠŸèƒ½éœ€æ±‚']):
                    in_non_functional_section = True
                    continue
                elif any(marker in line.lower() for marker in ['3. æµ‹è¯•åœºæ™¯', 'æµ‹è¯•åœºæ™¯:', 'æµ‹è¯•åœºæ™¯ï¼š', '### 3. æµ‹è¯•åœºæ™¯']):
                    in_non_functional_section = False
                    break
                elif in_non_functional_section:
                    # è¿‡æ»¤æ‰ç¼–å·å’Œç©ºè¡Œ
                    content = line
                    # å¤„ç†å¸¦æœ‰ç¼–å·ã€ç ´æŠ˜å·æˆ–å…¶ä»–æ ‡è®°çš„è¡Œ
                    if content.startswith(('-', '*', 'â€¢')):
                        content = content[1:].strip()
                    elif any(char.isdigit() for char in line[:2]):
                        for sep in ['.', 'ã€', 'ï¼‰', ')', ']']:
                            if sep in line:
                                try:
                                    content = line.split(sep, 1)[1]
                                    break
                                except IndexError:
                                    continue
                    content = content.strip()
                    # è¿‡æ»¤æ‰æ ‡é¢˜è¡Œã€ç©ºå†…å®¹å’Œç‰¹æ®Šæ ‡è®°
                    if content and not any(content.lower().startswith(prefix.lower()) for prefix in 
                        ['2.', 'äºŒã€', 'éåŠŸèƒ½éœ€æ±‚', 'éœ€æ±‚', 'è¦æ±‚', '**', '#']):
                        # å¦‚æœå†…å®¹ä»¥ç ´æŠ˜å·å¼€å¤´ï¼Œå»æ‰ç ´æŠ˜å·
                        if content.startswith('-'):
                            content = content[1:].strip()
                        non_functional_reqs.append(content)
            
            return non_functional_reqs
        except Exception as e:
            logger.error(f"æå–éåŠŸèƒ½éœ€æ±‚é”™è¯¯: {str(e)}")
            return []

    def _extract_test_scenarios(self, message: str) -> List[TestScenario]:
        """ä»ä»£ç†æ¶ˆæ¯ä¸­æå–æµ‹è¯•åœºæ™¯ï¼Œå¹¶è½¬æ¢ä¸ºTestScenarioå¯¹è±¡åˆ—è¡¨ã€‚"""
        try:
            if not message:
                logger.warning("è¾“å…¥æ¶ˆæ¯ä¸ºç©º")
                return []
                
            sections = message.split('\n')
            scenario_descriptions = []
            in_scenarios_section = False
            
            for line in sections:
                line = ''.join(char for char in line.strip() if ord(char) >= 32)
                if not line:
                    continue
                    
                # æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼
                if any(marker in line.lower() for marker in ['3. æµ‹è¯•åœºæ™¯', 'æµ‹è¯•åœºæ™¯:', 'æµ‹è¯•åœºæ™¯ï¼š', '### 3. æµ‹è¯•åœºæ™¯']):
                    in_scenarios_section = True
                    continue
                elif any(marker in line.lower() for marker in ['4. é£é™©é¢†åŸŸ', 'é£é™©é¢†åŸŸ:', 'é£é™©é¢†åŸŸï¼š', '### 4. é£é™©é¢†åŸŸ']):
                    in_scenarios_section = False
                    break
                elif in_scenarios_section:
                    # è¿‡æ»¤æ‰ç¼–å·å’Œç©ºè¡Œ
                    content = line
                    # å¤„ç†å¸¦æœ‰ç¼–å·ã€ç ´æŠ˜å·æˆ–å…¶ä»–æ ‡è®°çš„è¡Œ
                    if content.startswith(('-', '*', 'â€¢')):
                        content = content[1:].strip()
                    elif any(char.isdigit() for char in line[:2]):
                        for sep in ['.', 'ã€', 'ï¼‰', ')', ']']:
                            if sep in line:
                                try:
                                    content = line.split(sep, 1)[1]
                                    break
                                except IndexError:
                                    continue
                    content = content.strip()
                    # è¿‡æ»¤æ‰æ ‡é¢˜è¡Œã€ç©ºå†…å®¹å’Œç‰¹æ®Šæ ‡è®°
                    if content and not any(content.lower().startswith(prefix.lower()) for prefix in
                        ['3.', 'ä¸‰ã€', 'æµ‹è¯•åœºæ™¯', 'åœºæ™¯', '**', '#']):
                        # å¦‚æœå†…å®¹ä»¥ç ´æŠ˜å·å¼€å¤´ï¼Œå»æ‰ç ´æŠ˜å·
                        if content.startswith('-'):
                            content = content[1:].strip()
                        scenario_descriptions.append(content)
            
            # å°†æå–çš„æè¿°è½¬æ¢ä¸ºTestScenarioå¯¹è±¡
            test_scenarios = []
            for i, description in enumerate(scenario_descriptions):
                scenario_id = f"TS{(i+1):03d}"  # ç”Ÿæˆæ ¼å¼ä¸ºTS001, TS002çš„ID
                test_scenarios.append(TestScenario(
                    id=scenario_id,
                    description=description,
                    test_cases=[]
                ))
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•åœºæ™¯ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤åœºæ™¯
            if not test_scenarios:
                test_scenarios.append(TestScenario(
                    id="TS001",
                    description="éœ€è¦æä¾›å…·ä½“çš„æµ‹è¯•åœºæ™¯",
                    test_cases=[]
                ))
            
            return test_scenarios
        except Exception as e:
            logger.error(f"æå–æµ‹è¯•åœºæ™¯é”™è¯¯: {str(e)}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„TestScenarioå¯¹è±¡
            return [TestScenario(
                id="TS001",
                description="æå–æµ‹è¯•åœºæ™¯æ—¶å‘ç”Ÿé”™è¯¯",
                test_cases=[]
            )]

    def _extract_risk_areas(self, message: str) -> List[str]:
        """ä»ä»£ç†æ¶ˆæ¯ä¸­æå–é£é™©é¢†åŸŸã€‚"""
        try:
            if not message:
                logger.warning("è¾“å…¥æ¶ˆæ¯ä¸ºç©º")
                return []
                
            sections = message.split('\n')
            risk_areas = []
            in_risks_section = False
            
            for line in sections:
                line = ''.join(char for char in line.strip() if ord(char) >= 32)
                if not line:
                    continue
                    
                # æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼
                if any(marker in line.lower() for marker in ['4. é£é™©é¢†åŸŸ', 'é£é™©é¢†åŸŸ:', 'é£é™©é¢†åŸŸï¼š', '### 4. é£é™©é¢†åŸŸ']):
                    in_risks_section = True
                    continue
                elif line.startswith('5.') or not line.strip():
                    in_risks_section = False
                    break
                elif in_risks_section:
                    # è¿‡æ»¤æ‰ç¼–å·å’Œç©ºè¡Œ
                    content = line
                    # å¤„ç†å¸¦æœ‰ç¼–å·ã€ç ´æŠ˜å·æˆ–å…¶ä»–æ ‡è®°çš„è¡Œ
                    if content.startswith(('-', '*', 'â€¢')):
                        content = content[1:].strip()
                    elif any(char.isdigit() for char in line[:2]):
                        for sep in ['.', 'ã€', 'ï¼‰', ')', ']']:
                            if sep in line:
                                try:
                                    content = line.split(sep, 1)[1]
                                    break
                                except IndexError:
                                    continue
                    content = content.strip()
                    # è¿‡æ»¤æ‰æ ‡é¢˜è¡Œã€ç©ºå†…å®¹å’Œç‰¹æ®Šæ ‡è®°
                    if content and not any(content.lower().startswith(prefix.lower()) for prefix in 
                        ['4.', 'å››ã€', 'é£é™©é¢†åŸŸ', 'é£é™©', '**', '#']):
                        # å¦‚æœå†…å®¹ä»¥ç ´æŠ˜å·å¼€å¤´ï¼Œå»æ‰ç ´æŠ˜å·
                        if content.startswith('-'):
                            content = content[1:].strip()
                        risk_areas.append(content)
            
            return risk_areas
        except Exception as e:
            logger.error(f"æå–é£é™©é¢†åŸŸé”™è¯¯: {str(e)}")
            return []

    def _validate_analysis_result(self, result: Dict) -> bool:
        """éªŒè¯åˆ†æç»“æœçš„å®Œæ•´æ€§ã€‚"""
        required_keys = ['functional_requirements', 'non_functional_requirements', 
                        'test_scenarios', 'risk_areas']
        
        # æ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„é”®æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        for key in required_keys:
            if key not in result or not isinstance(result[key], list):
                return False
        return True

    def _fill_missing_requirements(self, result: Dict):
        """å¡«å……ç¼ºå¤±çš„éœ€æ±‚å­—æ®µã€‚"""
        default_value = ["éœ€è¦è¡¥å……å…·ä½“å†…å®¹"]
        required_keys = ['functional_requirements', 'non_functional_requirements', 
                        'test_scenarios', 'risk_areas']
        
        for key in required_keys:
            if key not in result or not result[key]:
                result[key] = default_value.copy()